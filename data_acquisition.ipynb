{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "from database_credentials import get_database_url\n",
    "from google_play_scraper import app, reviews, Sort\n",
    "from google_play_scraper.features.reviews import ContinuationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_review_data(data, connection):\n",
    "    \"\"\"Insert review data into local MySQL database\n",
    "    \n",
    "    Args:\n",
    "        data (dataframe): contains preprocessed review data\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    data.to_sql(\n",
    "        'reviews', \n",
    "        con=connection, \n",
    "        if_exists='append', \n",
    "        index=False,\n",
    "        method='multi'\n",
    "    )\n",
    "\n",
    "def save_continuation_token(continuation_token):\n",
    "    \"\"\"Unpack and save the google play scraper continuation token into a \n",
    "    JSON file - adapted from https://stackoverflow.com/questions/12309269/\n",
    "    \n",
    "    Args:\n",
    "        continuation_token (ContinuationToken): \n",
    "            indicates the next reviews to scraped\n",
    "            \n",
    "            refer to https://github.com/JoMingyu/google-play-scraper or\n",
    "            help(ContinuationToken) after importing ContinuationToken\n",
    "            from google_play_scraper.features.reviews\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    token_data = continuation_token.unpack()\n",
    "    with open('token_data.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(token_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_continuation_token():\n",
    "    \"\"\"Load and re-pack data into a google play scraper continuation token -\n",
    "    adapted from https://stackoverflow.com/questions/12309269/\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "            \n",
    "    Returns:\n",
    "        continuation_token (ContinuationToken): \n",
    "            indicates the next reviews to scraped\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('token_data.json', 'r', encoding='utf-8') as json_file:\n",
    "        token_data = json.load(json_file)\n",
    "\n",
    "    token_data = tuple(token_data)\n",
    "    continuation_token = ContinuationToken(*token_data)\n",
    "    return continuation_token\n",
    "\n",
    "def preprocess(data): \n",
    "    \"\"\"Load data into a dataframe and preprocess by dropping and renaming\n",
    "    features\n",
    "    \n",
    "    Args: \n",
    "        data (list): \n",
    "            data from google play scraper's reviews function\n",
    "            contains review data in the form of dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        preprocessed_data (dataframe):\n",
    "    \"\"\"\n",
    "    \n",
    "    column_names = [\n",
    "        'userName', 'content', 'score', \n",
    "        'reviewCreatedVersion', 'at'\n",
    "    ]\n",
    "    new_column_names = [\n",
    "        'user_id', 'review', 'rating', \n",
    "        'version', 'datetime_created'\n",
    "    ]\n",
    "    column_map = dict(zip(column_names, new_column_names))\n",
    "\n",
    "    preprocessed_data = pd.DataFrame(data) \n",
    "    preprocessed_data = preprocessed_data[column_names] # subset columns\n",
    "    preprocessed_data.rename(columns=column_map, inplace=True) # rename columns\n",
    "    return preprocessed_data\n",
    "\n",
    "def get_data(num_reviews):\n",
    "    \"\"\"Get review data by loading the continuation token, fetching, preprocessing \n",
    "    and inserting the review data and saving the new continuation token\n",
    "    \n",
    "    Args:\n",
    "        num_reviews (int): number of reviews to be fetched \n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        continuation_token = load_continuation_token()\n",
    "    except:\n",
    "        continuation_token = None\n",
    "\n",
    "    data, continuation_token = reviews(\n",
    "        'com.tgc.sky.android', \n",
    "        count=num_reviews, \n",
    "        continuation_token=continuation_token\n",
    "    )\n",
    "\n",
    "    review_data = preprocess(data)\n",
    "    \n",
    "    try:\n",
    "        insert_review_data(review_data, connection)\n",
    "        save_continuation_token(continuation_token)\n",
    "    except:\n",
    "        print('Failed to insert data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = get_database_url()\n",
    "engine = sqlalchemy.create_engine(database_url)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
